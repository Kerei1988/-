{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kerei1988/-/blob/main/myspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тема дипломной:\n",
        "# № 5. Анализ и сравнение различных способов обработки и хранения больших данных:\n",
        "# Pandas, Dask и Apache Spark"
      ],
      "metadata": {
        "id": "4JOWfJwfwSDS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aGBvSn8W4scz"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install pyspark\n",
        "!pip install pandas\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HbyQNhrdUZGd"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession, DataFrame, Row\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.sql.functions import *\n",
        "from collections import defaultdict\n",
        "from pyspark.sql.types import FloatType, DecimalType, IntegerType\n",
        "\n",
        "\n",
        "\n",
        "# Открываем сессию Spark, для чтения базы данных с файла, для дальнейшей обратботки и анализа\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Читаем файл csv\n",
        "sdf = spark.read.option('multiline', True).csv('Data-Science-Jobs.csv', header=True)\n",
        "\n",
        "# Визуальный осмотр данных (первые 5 строк)\n",
        "sdf.show(5, truncate=100)\n",
        "\n",
        "# Информация о базе данных: база данных сотсовляет из 500 строк,\n",
        "# столбцы  ' Salary', '  Logo ', ' Company Rating' включают пропущенные значени\n",
        "# Столбцы 'Salary' и 'Company Rating',  'Date' - тип данных String,\n",
        "sdf.printSchema()\n",
        "sdf.describe().show()\n",
        "\n",
        "# Около 13% строк, содержащие не заполненные поля,  удаляем. Для анализа данных останется 387 строк\n",
        "df = sdf.dropna()\n",
        "df_count = df.count()\n",
        "print(df_count)\n",
        "df.describe().show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nMQOl-Q0eIXV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TOP 10 популярныx региона США, для найма специалистов в области обработки данных , визуализируем для удобного восприятия.\n",
        "# график показывает что наибольшее количество вакансий Riverwoods, IL(31), Remote (22), New York, NY (21)\n",
        "location = df.groupBy('Location').count().orderBy('count', ascending=False)\n",
        "pandas_location = location.toPandas().set_index('Location').head(10)\n",
        "pandas_location.plot.bar()\n",
        "\n",
        "# Найдем города с наибольши и наименьшим спросом на специалистов.\n",
        "# Количество вакансии меньше 6 - 117 регион\n",
        "# Количество вакинсий больше 15 - 3 региона\n",
        "small_location = location.filter(location['count'] <= 5)\n",
        "print(small_location.count())\n",
        "most_location = location.filter(location['count'] >= 15)\n",
        "print(most_location.count())\n",
        "# количество специальностей - 223\n",
        "number_specialists = df.select('Job Title').drop_duplicates()\n",
        "number_specialists.count()\n",
        "\n",
        "# Самые востребованные специалисты:\n",
        "# 1 -  Data Scientist\n",
        "# 2 - Senior Data Scientist\n",
        "# 3 - Senior Manager Data Scientist, Principal Data Science\n",
        "most_popular_specialties = df.groupBy('Job Title').count().sort('count', ascending=False).show(truncate=100)\n",
        "\n",
        "# количество наименее востребованных специалистов, с одной вакансией на рынке труда - 154 вакансий\n",
        "least_popular_specialties = df.groupBy('Job Title').count().filter('count < 2').count()\n",
        "print(least_popular_specialties)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwuYbibs2gEy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxNY6FfB0KQz",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# найдем среднее количество дней актуальности вакансий - 19+\n",
        "# минимальный срок актуальности - 1\n",
        "# максимальное количество дней - 30\n",
        "date_df = df[['Date']]\n",
        "date_df = date_df.withColumn('Date', regexp_replace('Date', '24h', '1d'))\n",
        "date_df = date_df.withColumn('Date', regexp_extract('Date', r'\\b(\\d+).+', 1).astype(IntegerType()))\n",
        "date_min = date_df.select(min(date_df.Date)).show()\n",
        "date_max = date_df.agg({'Date': 'max'}).show()\n",
        "date_mean = date_df.select(mean(date_df.Date)).show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# найдем самого активного работодателя на рынке труда из базы данных - 'Discover Financial Services' (31 вакания)\n",
        "# Общее количество работодателей 188\n",
        "# Количество компаний с одной вакансией на рынке труда -117\n",
        "# отобразим на графике 10 самых активных работодателей\n",
        "\n",
        "company_name = df[['Company Name']].withColumn('Company Name', regexp_replace('Company Name', '(\\n\\d\\.\\d)', ''))\n",
        "number_vacancies_per_company = company_name.groupBy('Company Name').count().sort('count', ascending=False) # Количество вакансий на 1 работодателя\n",
        "number_vacancies = number_vacancies_per_company.filter(number_vacancies_per_company['count'] < 2).drop_duplicates().count() #\n",
        "print(number_vacancies)\n",
        "number_companies = company_name.drop_duplicates().count() #количество работодателей\n",
        "\n",
        "# десятка самых активных работодателей базы данных\n",
        "part = number_vacancies_per_company.withColumn('count', (number_vacancies_per_company['count']/number_companies)*100)\n",
        "part_pandas = part.toPandas().set_index('Company Name').head(10)\n",
        "part_pandas.plot.barh()\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "56mHi3i9_UId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Для анализа рынка труда, нужно столбец \"Salary\", преобразовать в числовой тип\n",
        "\n",
        "salary = df[['Job Title', 'Salary']].withColumn('Salary', translate('Salary', '$|K', '').alias('Salary'))\n",
        "salary_per = salary.filter(salary.Salary.like('%Per%'))\n",
        "salary_month = salary.join(salary_per[['Job Title', 'Salary']], 'Salary', how='left_anti')\n",
        "\n",
        "salary_per =  salary_per.withColumn('Salary', regexp_extract('Salary', '(\\d\\d.\\d\\d - \\d\\d.\\d\\d)|(\\d\\d)', 0))\n",
        "salary_per = salary_per.withColumn('Salary_1', split('Salary', '-')[1].cast(DecimalType(5,2)))\n",
        "salary_per = salary_per.withColumn('Salary_0', split('Salary', '-')[0])\n",
        "salary_per = salary_per.withColumn('Salary', coalesce((col('Salary_1')+col('Salary_0'))/2, lit(salary_per['Salary_0'])))\n",
        "salary_per = salary_per.withColumn('Salary', col('Salary')*8*22/1000)\n",
        "salary_per = salary_per.withColumn('Salary, $, K', col('Salary').cast(DecimalType(5,2)))\n",
        "salary_per = salary_per.select('Job Title', 'Salary, $, K')\n",
        "\n",
        "salary_month = salary_month.withColumn('Salary', translate('Salary', ' ', ''))\n",
        "salary_month = salary_month.withColumn('Salary', regexp_extract('Salary', '\\d+-\\d+|\\d+', 0))\n",
        "salary_month = salary_month.withColumn('Salary_1', split('Salary', '-')[1].cast(DecimalType(5,2)))\n",
        "salary_month = salary_month.withColumn('Salary_0', split('Salary', '-')[0])\n",
        "salary_month = salary_month.withColumn('Salary, $, K', coalesce((col('Salary_1')+col('Salary_0'))/2, lit(salary_month['Salary_0'])).cast(DecimalType(5,2)))\n",
        "salary_month = salary_month.select('Job Title', 'Salary, $, K')\n",
        "\n",
        "# Преобразованная таблица 'Salary'\n",
        "salary = salary_month.join(salary_per, ['Job Title', 'Salary, $, K'], how='outer')\n",
        "\n",
        "# Максимальная оплата труда - 4 вакансии 'Reliability, Availability and Serviceability Expert, Datacenter AI Products Development'($272.5 K) от компании NVIDIA\n",
        "# Минимальная - Junior Data Science ($2.46 K)\n",
        "salary_max = salary.orderBy('Salary, $, K', ascending=False)\n",
        "salary_min = salary.orderBy('Salary, $, K', ascending=True)\n",
        "\n",
        "#Средняя заработная плата по рынку состовляет 117.405\n",
        "avg_salary = salary.agg({'Salary, $, K': 'mean'})\n",
        "\n",
        "# Лучшие работодатели по рейтингу\n",
        "rating_company = df[['Company Name', 'Company Rating']]\n",
        "rating_company = df[['Company Name','Company Rating']].withColumn('Company Name', regexp_replace('Company Name', '(\\n\\d\\.\\d)', '')).sort('Company Rating', ascending=False)\n",
        "pandas_rating = rating_company.toPandas().set_index('Company Name').astype(float).drop_duplicates().head(10)\n",
        "pandas_rating.plot.barh()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KLfXkYX98SMg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMs8XZ20Y7npWWl1yFwXTGC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}